# Discriminator
**Dataset**

This is a discriminator that has three inputs: 

1) a caption

2) the an actual that matched that caption

3) an image that has been generated by a generator using that caption. 

The discriminator needs to differentiate between the generated image and the actual image. 

The images were 224 X 224 X 3 pixels in size.

**Architecture**

I used a vanilla CNN to acheive good results for this model. I tried transfer learning with mobile net, but just a vanilla CNN gave the best results.

I used a single input to the vanilla CNN, which gave score of how likely that image was the real one. So I fed both the inputs to the CNN and then picked the one with the higher score as the real image. This increased accuracy by 10-15% compared to just using the CNN on one of the imeages and having a threshold to decide if it is real or not. 

I experimented and tuned with different architectures and layer sizes and the one that gave the best results was 4 Convolution 2D layers all having 64 units and a filter of 3 X 3, followed by 4 dense layers of 1024, 512, 256 and 1 units respectively.

I tried varying architectures with tuning and this gave the best results. 

I also added Average Pooling 2D layers, and Batch Normalization layers. This handles the vanising gradient problem, and further increased accuracy.

A learnig rate of 0.01 produced the best results after tuning.

I ran the trials for 128 epocks with early stopping callback.

**Results**

This achieved a stellar accuracy of 96.55% on the test set. 
